/robots.txt revealed url /.hidden

26 top-level directories and one README, each seem to have 26 sub-level subdirs and one README, and so on...
created crawler script to go through it all and find the content of all READMEs